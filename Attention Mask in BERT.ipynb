{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attention Mask in BERT\n",
    "\n",
    "The attention_mask tensor indicates which tokens should be attended to (1) and which tokens are padding (0) and should be ignored. This is \n",
    "particularly important when dealing with batches of sequences of varying lengths.\n",
    "\n",
    "Suppose we have two sentences of different lengths, and we want to process them in a batch. We use padding to make them the same length, and the \n",
    "attention_mask will indicate which tokens are real and which are padding.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "KoG0HBvdywTc"
   },
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "G8y7gwaIzyTR",
    "outputId": "c2f981a5-1fbd-4915-ec13-ce7c0e417ece"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Orginal text sequences batch:\n",
      " ['The children enjoyed a picnic by the river bank, watching ducks swim by.', 'They relaxed as the sun set.']\n"
     ]
    }
   ],
   "source": [
    "Text_sequences = [\"The children enjoyed a picnic by the river bank, watching ducks swim by.\", \"They relaxed as the sun set.\"]\n",
    "print(\"Orginal text sequences batch:\\n\", Text_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wiMYTHmJz3P1",
    "outputId": "74e3971f-56d7-44b6-e294-6249e6aaf994"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessed text sequences batch:\n",
      " ['child enjoyed picnic river bank watching duck swim', 'relaxed sun set']\n"
     ]
    }
   ],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def preprocess(text):\n",
    "    tokens = word_tokenize(text.lower())\n",
    "    tokens = [lemmatizer.lemmatize(token) for token in tokens if token not in stop_words and token not in string.punctuation]\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "preprocessed_Text_sequences = [(preprocess(text_sequence)) for text_sequence in Text_sequences]\n",
    "print(\"Preprocessed text sequences batch:\\n\", preprocessed_Text_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "05LnHdUAz_BN"
   },
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertModel.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "YDFigN5C0HZi"
   },
   "outputs": [],
   "source": [
    "def generate_embedding(preprocessed_Text_sequences):\n",
    "    inputs = tokenizer(preprocessed_Text_sequences,  padding=True, return_tensors='pt')\n",
    "    bert_tokenized_text = [tokenizer.convert_ids_to_tokens(ids) for ids in inputs['input_ids']]\n",
    "    print(\"BERT tokens for text sequences batch:\\n\", bert_tokenized_text)\n",
    "    print(\"BERT attention_mask for text sequences batch:\\n\", inputs['attention_mask'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9YZQjjYR0NXd",
    "outputId": "7a30e2a8-e181-4c68-8a7f-345173008cf4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BERT tokens for text sequences batch:\n",
      " [['[CLS]', 'child', 'enjoyed', 'picnic', 'river', 'bank', 'watching', 'duck', 'swim', '[SEP]'], ['[CLS]', 'relaxed', 'sun', 'set', '[SEP]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]']]\n",
      "BERT attention_mask for text sequences batch:\n",
      " tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 0, 0, 0, 0, 0]])\n"
     ]
    }
   ],
   "source": [
    "individual_word_embeddings_for_batch_of_sentences = generate_embedding(preprocessed_Text_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zXYKxWNJ0SAg"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
